{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/olalepek/PySpark_CNN_Article_Frequent_Items/blob/main/Articles_CNN_Frequent_Items_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Frequent words recognition in the CNN articles and articles highlights using FPG Growth model in Pyspark and Apriori Alghoritm using Pandas**\n",
        "\n",
        "1. Data source: https://www.kaggle.com/datasets/gowrishankarp/newspaper-text-summarization-cnn-dailymail\n",
        "2. Analysis of the highlights & article text with different sensitivities\n",
        "3. Analysis of the highlights using pandas for the comparison of the computationl efficiency"
      ],
      "metadata": {
        "id": "NSDy93Lbnj3w"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFB_GgxkJTgK"
      },
      "source": [
        "# Setting up Kaggle "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ihZnfOOBXQ40"
      },
      "outputs": [],
      "source": [
        "import timeit\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import kaggle"
      ],
      "metadata": {
        "id": "78CzrKQhM7q3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "outputId": "41f5de57-0d9a-4b01-fc67-7a60f2a4d417"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-2e5e3441a2d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mkaggle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/kaggle/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mapi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKaggleApi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mApiClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauthenticate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/kaggle/api/kaggle_api_extended.py\u001b[0m in \u001b[0;36mauthenticate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    162\u001b[0m                 \u001b[0mconfig_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_config_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m                 raise IOError('Could not find {}. Make sure it\\'s located in'\n\u001b[0m\u001b[1;32m    165\u001b[0m                               ' {}. Or use the environment method.'.format(\n\u001b[1;32m    166\u001b[0m                                   self.config_file, self.config_dir))\n",
            "\u001b[0;31mOSError\u001b[0m: Could not find kaggle.json. Make sure it's located in /root/.kaggle. Or use the environment method."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dj8b7pZ_XZsz"
      },
      "outputs": [],
      "source": [
        "!pip install -q kaggle\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Uploading the key .json file to access Kaggle"
      ],
      "metadata": {
        "id": "wSCS5AaiL9mj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "mOXnl9uoXZ0M",
        "outputId": "40d5b667-823a-4e76-8475-2e5b72fb6a3c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-5fc4118f-ee6a-4115-8586-ef06037ca5c0\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-5fc4118f-ee6a-4115-8586-ef06037ca5c0\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"olalepek\",\"key\":\"73bdd01d581a194b39d3e51c94a4bf92\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "# https://www.kaggle.com/general/74235\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QIlqp1plXZ3J"
      },
      "outputs": [],
      "source": [
        "!cp kaggle.json ~/.kaggle/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xCSHJV0LXZ5w"
      },
      "outputs": [],
      "source": [
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ib43RJL0BT0E"
      },
      "source": [
        "#  CNN Article  Market Basket Analysis in PySpark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tx9IcYV6E1AX"
      },
      "source": [
        "## Setting up PySpark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OU88Ys7wE62k"
      },
      "outputs": [],
      "source": [
        "# Download Java Virtual Machine (JVM)\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eE9XQVacE65L"
      },
      "outputs": [],
      "source": [
        "# Download Spark\n",
        "!wget -q https://dlcdn.apache.org/spark/spark-3.3.2/spark-3.3.2-bin-hadoop3.tgz\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_zfVA4jzE68C"
      },
      "outputs": [],
      "source": [
        "!tar -xf '/content/spark-3.3.2-bin-hadoop3.tgz'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8R__LLdME6-m"
      },
      "outputs": [],
      "source": [
        "# Set up the enviornment\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = '/usr/lib/jvm/java-8-openjdk-amd64'\n",
        "os.environ[\"SPARK_HOME\"] = '/content/spark-3.3.2-bin-hadoop3'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yYO3_uEAE7A8"
      },
      "outputs": [],
      "source": [
        "# Install library for finding Spark\n",
        "!pip install -q findspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZZttpUDSGUhk"
      },
      "outputs": [],
      "source": [
        "# Import the libary\n",
        "import findspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "euKWIoMFGUes"
      },
      "outputs": [],
      "source": [
        "# Initiate findspark\n",
        "findspark.init()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HV9oTh-vGUSv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "a558358d-9c4b-49aa-9a0f-ac346e3ba2ee"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f40c1cbf520>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://ee1a793c14a9:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.3.2</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# Import SparkSession\n",
        "from pyspark.sql import SparkSession\n",
        "# Create a Spark Session\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "# Check Spark Session Information\n",
        "spark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "087GGqkwJD1T"
      },
      "outputs": [],
      "source": [
        "# Import a Spark function from library to verify\n",
        "from pyspark.sql.functions import col"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading dataset"
      ],
      "metadata": {
        "id": "wX-ti5Ts_Amr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xsTxW4eISAIL"
      },
      "outputs": [],
      "source": [
        "# https://www.kaggle.com/code/sercanyesiloz/pyspark-tutorial/notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tukB15t-CVWS",
        "outputId": "ca33fc12-9f0b-4023-fdad-5c603fbe5017"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading newspaper-text-summarization-cnn-dailymail.zip to /content\n",
            "100% 501M/503M [00:21<00:00, 25.5MB/s]\n",
            "100% 503M/503M [00:21<00:00, 24.4MB/s]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!kaggle datasets download -d gowrishankarp/newspaper-text-summarization-cnn-dailymail"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kwu_iZ9UCVpI",
        "outputId": "df05b4bd-057b-4f1f-a27e-57af39ed8880"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/newspaper-text-summarization-cnn-dailymail.zip\n",
            "  inflating: /content/CNN/cnn_dailymail/test.csv  \n",
            "  inflating: /content/CNN/cnn_dailymail/train.csv  \n",
            "  inflating: /content/CNN/cnn_dailymail/validation.csv  \n"
          ]
        }
      ],
      "source": [
        "!unzip /content/newspaper-text-summarization-cnn-dailymail.zip -d /content/CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JpNjlVA8CVr-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb2d1fc6-6abd-4375-c526-847fcdfada87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- id: string (nullable = true)\n",
            " |-- article: string (nullable = true)\n",
            " |-- highlights: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "df = spark \\\n",
        "    .read \\\n",
        "    .format(\"csv\") \\\n",
        "    .option(\"header\", True) \\\n",
        "    .load(\"/content/CNN/cnn_dailymail\")\n",
        "\n",
        "df.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6GArH5xID6Jz",
        "outputId": "e80105d7-cfce-4d82-f6bd-cb32fc12f485"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+--------------------+\n",
            "|                  id|             article|          highlights|\n",
            "+--------------------+--------------------+--------------------+\n",
            "|0001d1afc246a7964...|By . Associated P...|Bishop John Folda...|\n",
            "|He contracted the...|                null|                null|\n",
            "|Church members in...| Grand Forks and ...|                null|\n",
            "|0002095e55fcbd3a2...|\"(CNN) -- Ralph M...|\"\" of using his r...|\n",
            "|          Ralph Mata| an internal affa...| allegedly helped...|\n",
            "+--------------------+--------------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xRfRFsUONSD2",
        "outputId": "20ba5116-3313-41eb-d6e2-090b484061a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "42"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Removing the rows with the NULL values"
      ],
      "metadata": {
        "id": "uDtUHTchNaKj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.dropna()"
      ],
      "metadata": {
        "id": "Uv_YROkPSsyp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNAdu63YDDQR"
      },
      "source": [
        "## Data Pre-processing - Highlights"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Renaming the highlights column to text - as this is what we will start to analyse"
      ],
      "metadata": {
        "id": "Nabr47jRNlOw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.withColumnRenamed(\"highlights\", \"text\")"
      ],
      "metadata": {
        "id": "0tw1mXc_ZnrY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LX--vjZfZxpo",
        "outputId": "ddc27631-6c95-4019-f438-8a992e80c2d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+--------------------+\n",
            "|                  id|             article|                text|\n",
            "+--------------------+--------------------+--------------------+\n",
            "|0001d1afc246a7964...|By . Associated P...|Bishop John Folda...|\n",
            "|0002095e55fcbd3a2...|\"(CNN) -- Ralph M...|\"\" of using his r...|\n",
            "|          Ralph Mata| an internal affa...| allegedly helped...|\n",
            "|00027e965c8264c35...|A drunk driver wh...|Craig Eccleston-T...|\n",
            "|0002c17436637c4fe...|(CNN) -- With a b...|Nina dos Santos s...|\n",
            "+--------------------+--------------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Removing any links, punctuation, numbers - useful for the tweets or other social media sourced text"
      ],
      "metadata": {
        "id": "tnwB8Sv6ODIh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G9DZFn39CVu2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe43002d-9c62-4725-8583-4aacb534aa17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+--------------------+\n",
            "|                  id|             article|                text|\n",
            "+--------------------+--------------------+--------------------+\n",
            "|0001d1afc246a7964...|By . Associated P...|Bishop John Folda...|\n",
            "|0002095e55fcbd3a2...|\"(CNN) -- Ralph M...|\"\" of using his r...|\n",
            "|          Ralph Mata| an internal affa...| allegedly helped...|\n",
            "|00027e965c8264c35...|A drunk driver wh...|Craig Eccleston T...|\n",
            "|0002c17436637c4fe...|(CNN) -- With a b...|Nina dos Santos s...|\n",
            "|0003ad6ef0c37534f...|Fleetwood are the...|Fleetwood top of ...|\n",
            "|        Peterborough|        Bristol City| Chesterfield and...|\n",
            "|0004306354494f090...|He's been accused...|Prime Minister an...|\n",
            "|0005d61497d21ff37...|By . Daily Mail R...|NBA star calls fo...|\n",
            "|0006021f772fad0aa...|\"By . Daily Mail ...| other passengers...|\n",
            "+--------------------+--------------------+--------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import regexp_replace\n",
        "\n",
        "\n",
        "# Remove links, punctuation (REGEX provided) and numbers\n",
        "df = df.withColumn('text', regexp_replace(df.text, 'https://t.co/', ' '))\n",
        "df = df.withColumn('text', regexp_replace(df.text, '[_#()%&:;,.!?\\\\-]', ' '))\n",
        "df = df.withColumn('text', regexp_replace(df.text, '[0-9]', ' '))\n",
        "\n",
        "# Merge multiple spaces\n",
        "df = df.withColumn('text', regexp_replace(df.text, ' +', ' '))\n",
        "\n",
        "df.show(10)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[\"id\",\"text\"]"
      ],
      "metadata": {
        "id": "0x2Bp-zsOzg4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PzRgQcCEO6pz",
        "outputId": "873c60db-5746-4f27-c379-a4e35399fa47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+\n",
            "|                  id|                text|\n",
            "+--------------------+--------------------+\n",
            "|0001d1afc246a7964...|Bishop John Folda...|\n",
            "|0002095e55fcbd3a2...|\"\" of using his r...|\n",
            "|          Ralph Mata| allegedly helped...|\n",
            "|00027e965c8264c35...|Craig Eccleston T...|\n",
            "|0002c17436637c4fe...|Nina dos Santos s...|\n",
            "|0003ad6ef0c37534f...|Fleetwood top of ...|\n",
            "|        Peterborough| Chesterfield and...|\n",
            "|0004306354494f090...|Prime Minister an...|\n",
            "|0005d61497d21ff37...|NBA star calls fo...|\n",
            "|0006021f772fad0aa...| other passengers...|\n",
            "+--------------------+--------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Converting text into tokens and removing any stop words that don't bring meaning to the understanding of the text"
      ],
      "metadata": {
        "id": "XS81XVjZOb_X"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EEx2iiilDKfW"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.feature import Tokenizer,StopWordsRemover, CountVectorizer,IDF,StringIndexer\n",
        "from pyspark.ml.feature import Tokenizer, RegexTokenizer\n",
        "from pyspark.sql.functions import col, udf, concat_ws\n",
        "from pyspark.sql.types import IntegerType\n",
        "\n",
        "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"tokens\")\n",
        "regexTokenizer = RegexTokenizer(inputCol=\"text\", outputCol=\"tokens\", pattern=\"\\\\W\")\n",
        "stopremove = StopWordsRemover(inputCol='tokens',outputCol='cleaned')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating pipline to apply the above methods to our dataframe"
      ],
      "metadata": {
        "id": "XaAh3s9JOt1f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml import Pipeline\n",
        "data_prep_pipe = Pipeline(stages=[regexTokenizer, stopremove ])\n",
        "cleaner = data_prep_pipe.fit(df)\n",
        "df = cleaner.transform(df)"
      ],
      "metadata": {
        "id": "0kQ71784Ks-W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Collecting the garbage to keep the workspace clean and free up memory"
      ],
      "metadata": {
        "id": "K0bVzOnkOzaX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bAd8KdxjGEK1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecc4dac9-7e96-45ac-c526-1b1ca1d0e757"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "263"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "import gc\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6wbcRx1JNYoC",
        "outputId": "39b8763f-644e-456f-ba64-3ab268943b4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+--------------------+--------------------+\n",
            "|                  id|                text|              tokens|             cleaned|\n",
            "+--------------------+--------------------+--------------------+--------------------+\n",
            "|0001d1afc246a7964...|Bishop John Folda...|[bishop, john, fo...|[bishop, john, fo...|\n",
            "|0002095e55fcbd3a2...|\"\" of using his r...|[of, using, his, ...|[using, role, pol...|\n",
            "|          Ralph Mata| allegedly helped...|[allegedly, helpe...|[allegedly, helpe...|\n",
            "|00027e965c8264c35...|Craig Eccleston T...|[craig, eccleston...|[craig, eccleston...|\n",
            "|0002c17436637c4fe...|Nina dos Santos s...|[nina, dos, santo...|[nina, dos, santo...|\n",
            "+--------------------+--------------------+--------------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Calculating the average number of tokens per row"
      ],
      "metadata": {
        "id": "3dHefORzQKNx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import IntegerType\n",
        "from pyspark.sql.functions import collect_set, array_distinct"
      ],
      "metadata": {
        "id": "L9WvWAjLq64q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "baskets = df.select(array_distinct(df.cleaned)).collect()\n",
        "baskets = spark.createDataFrame(baskets)"
      ],
      "metadata": {
        "id": "n8tYljKqTw4C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "baskets.show(5, False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-6zj4VkXUUi",
        "outputId": "ad66a83b-16e3-4896-ed64-11d9b68f23bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------------------------------------------------------------------------------+\n",
            "|array_distinct(cleaned)                                                                      |\n",
            "+---------------------------------------------------------------------------------------------+\n",
            "|[bishop, john, folda, north, dakota, taking, time, diagnosed]                                |\n",
            "|[using, role, police, officer, help, drug, trafficking, organization, exchange, money, gifts]|\n",
            "|[allegedly, helped, group, get, guns]                                                        |\n",
            "|[craig, eccleston, todd, drunk, least, three, pints, driving, car]                           |\n",
            "|[nina, dos, santos, says, europe, must, ready, accept, sanctions, hurt, sides]               |\n",
            "+---------------------------------------------------------------------------------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count_tokens = udf(lambda words:len(words), IntegerType())\n",
        "baskets = baskets.withColumn('count', count_tokens(col('array_distinct(cleaned)')))\n"
      ],
      "metadata": {
        "id": "1PgkcVGwP9Kn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "baskets.describe().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QjnR8OEYRXde",
        "outputId": "fa4068e0-6c2a-4a9f-b38b-8dcb9f149b35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----------------+\n",
            "|summary|            count|\n",
            "+-------+-----------------+\n",
            "|  count|           382518|\n",
            "|   mean|7.969055051004136|\n",
            "| stddev|5.965069522183348|\n",
            "|    min|                0|\n",
            "|    max|              222|\n",
            "+-------+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Models for Highlights"
      ],
      "metadata": {
        "id": "OWqKJuuUXONi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import IntegerType\n",
        "from pyspark.sql.functions import collect_set, array_distinct\n",
        "from pyspark.ml.fpm import FPGrowth\n",
        "\n"
      ],
      "metadata": {
        "id": "Lwx2dFg9LiHC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model with min support = 0.05"
      ],
      "metadata": {
        "id": "3coHEwc8TDbK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "1.   Creating baskets - making sure that the rows have distinct \n",
        "2.   Setting up the model\n",
        "3. Showing the top 10 results of most frequent items or items pairs\n"
      ],
      "metadata": {
        "id": "FVg3RUjwPlxs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start = timeit.default_timer()\n",
        "fpGrowth = FPGrowth(minSupport=0.05, minConfidence=1, itemsCol=\"array_distinct(cleaned)\")\n",
        "model = fpGrowth.fit(baskets)\n",
        "model.freqItemsets.show(10, False)\n",
        "highlights_05 = timeit.default_timer() - start"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ytiJelrGTw01",
        "outputId": "b0b2ae6c-b483-4c8b-ae2a-e570405abafb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----+\n",
            "|items |freq |\n",
            "+------+-----+\n",
            "|[said]|29765|\n",
            "+------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "highlights_05"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWosHwf7Uj-y",
        "outputId": "d0ab58fc-9b3e-4e35-aaac-a9b3c81f3468"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7.6207929269994565"
            ]
          },
          "metadata": {},
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Model with min support = 0.005"
      ],
      "metadata": {
        "id": "V711NigqUPci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start = timeit.default_timer()\n",
        "fpGrowth = FPGrowth(minSupport=0.005, minConfidence=1, itemsCol=\"array_distinct(cleaned)\")\n",
        "model = fpGrowth.fit(baskets)\n",
        "model.freqItemsets.show(10, False)\n",
        "highlights_005 = timeit.default_timer() - start"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3JE7vg3KTwqu",
        "outputId": "0b6b0934-b0de-4d02-9234-2f7b01eac0d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+----+\n",
            "|items     |freq|\n",
            "+----------+----+\n",
            "|[today]   |2720|\n",
            "|[minister]|1978|\n",
            "|[news]    |2335|\n",
            "|[go]      |2540|\n",
            "|[park]    |2158|\n",
            "|[car]     |3067|\n",
            "|[family]  |4126|\n",
            "|[sunday]  |3578|\n",
            "|[told]    |8415|\n",
            "|[west]    |2879|\n",
            "+----------+----+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "highlights_005"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MC_QaSY9UsPC",
        "outputId": "c79bfb51-bcd0-490e-9567-433552427411"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10.809896277000007"
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.associationRules.show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2N2AN8OIW9CE",
        "outputId": "8e26ac2b-e15b-4704-df93-dad29ab0a16c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+----------+----------+----+-------+\n",
            "|antecedent|consequent|confidence|lift|support|\n",
            "+----------+----------+----------+----+-------+\n",
            "+----------+----------+----------+----+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Model with min support = 0.0005"
      ],
      "metadata": {
        "id": "F9GRkTbHUwIQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start = timeit.default_timer()\n",
        "fpGrowth = FPGrowth(minSupport=0.0005, minConfidence=1, itemsCol=\"array_distinct(cleaned)\")\n",
        "model2 = fpGrowth.fit(baskets)\n",
        "model2.freqItemsets.show(10, False)\n",
        "highlights_0005 = timeit.default_timer() - start"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rsX_DdOmYIQd",
        "outputId": "08e4807c-c553-4fb1-c6c7-aade12677dc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+----+\n",
            "|items        |freq|\n",
            "+-------------+----+\n",
            "|[announce]   |246 |\n",
            "|[insurance]  |290 |\n",
            "|[singer]     |639 |\n",
            "|[grand]      |896 |\n",
            "|[trade]      |331 |\n",
            "|[wounds]     |216 |\n",
            "|[today]      |2720|\n",
            "|[today, said]|295 |\n",
            "|[isn]        |383 |\n",
            "|[defender]   |498 |\n",
            "+-------------+----+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "highlights_0005"
      ],
      "metadata": {
        "id": "7ho_d06eV73D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a16b335b-f06d-4ae7-d054-b69f078e8ec9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "109.58784816499997"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "pfKwDki6YZpY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c00ce81-1904-415b-e566-b287de2ea70f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "45"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2.associationRules.show(10)"
      ],
      "metadata": {
        "id": "B0t00EcWU4bO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "17f823d6-871c-4619-c348-4ca86ecf0802"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "Py4JJavaError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-e749fa0fc186>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massociationRules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/spark-3.3.2-bin-hadoop3/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtruncate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 606\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    607\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.3.2-bin-hadoop3/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1322\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.3.2-bin-hadoop3/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.3.2-bin-hadoop3/python/lib/py4j-0.10.9.5-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOUTPUT_CONVERTER\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway_client\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mREFERENCE_TYPE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m                 raise Py4JJavaError(\n\u001b[0m\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m                     format(target_id, \".\", name), value)\n",
            "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o164.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 10.0 failed 1 times, most recent failure: Lost task 0.0 in stage 10.0 (TID 34) (ee1a793c14a9 executor driver): java.lang.OutOfMemoryError: Java heap space\n\tat java.util.IdentityHashMap.resize(IdentityHashMap.java:474)\n\tat java.util.IdentityHashMap.put(IdentityHashMap.java:443)\n\tat org.apache.spark.util.SizeEstimator$SearchState.enqueue(SizeEstimator.scala:174)\n\tat org.apache.spark.util.SizeEstimator$.visitArray(SizeEstimator.scala:252)\n\tat org.apache.spark.util.SizeEstimator$.visitSingleObject(SizeEstimator.scala:209)\n\tat org.apache.spark.util.SizeEstimator$.estimate(SizeEstimator.scala:201)\n\tat org.apache.spark.util.SizeEstimator$.$anonfun$sampleArray$1(SizeEstimator.scala:285)\n\tat org.apache.spark.util.SizeEstimator$$$Lambda$2199/1314312644.apply$mcVI$sp(Unknown Source)\n\tat scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:158)\n\tat org.apache.spark.util.SizeEstimator$.sampleArray(SizeEstimator.scala:277)\n\tat org.apache.spark.util.SizeEstimator$.visitArray(SizeEstimator.scala:261)\n\tat org.apache.spark.util.SizeEstimator$.visitSingleObject(SizeEstimator.scala:209)\n\tat org.apache.spark.util.SizeEstimator$.estimate(SizeEstimator.scala:201)\n\tat org.apache.spark.util.SizeEstimator$.estimate(SizeEstimator.scala:68)\n\tat org.apache.spark.util.collection.SizeTracker.takeSample(SizeTracker.scala:78)\n\tat org.apache.spark.util.collection.SizeTracker.afterUpdate(SizeTracker.scala:70)\n\tat org.apache.spark.util.collection.SizeTracker.afterUpdate$(SizeTracker.scala:67)\n\tat org.apache.spark.util.collection.SizeTrackingAppendOnlyMap.changeValue(SizeTrackingAppendOnlyMap.scala:33)\n\tat org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:164)\n\tat org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)\n\tat org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:116)\n\tat org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:106)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2672)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2608)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2607)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2607)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1182)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1182)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1182)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2860)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2802)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2791)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:952)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2238)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2259)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2278)\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:506)\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:459)\n\tat org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:48)\n\tat org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:3868)\n\tat org.apache.spark.sql.Dataset.$anonfun$head$1(Dataset.scala:2863)\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$2(Dataset.scala:3858)\n\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:510)\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3856)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:109)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:169)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:95)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:779)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3856)\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:2863)\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:3084)\n\tat org.apache.spark.sql.Dataset.getRows(Dataset.scala:288)\n\tat org.apache.spark.sql.Dataset.showString(Dataset.scala:327)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: java.lang.OutOfMemoryError: Java heap space\n\tat java.util.IdentityHashMap.resize(IdentityHashMap.java:474)\n\tat java.util.IdentityHashMap.put(IdentityHashMap.java:443)\n\tat org.apache.spark.util.SizeEstimator$SearchState.enqueue(SizeEstimator.scala:174)\n\tat org.apache.spark.util.SizeEstimator$.visitArray(SizeEstimator.scala:252)\n\tat org.apache.spark.util.SizeEstimator$.visitSingleObject(SizeEstimator.scala:209)\n\tat org.apache.spark.util.SizeEstimator$.estimate(SizeEstimator.scala:201)\n\tat org.apache.spark.util.SizeEstimator$.$anonfun$sampleArray$1(SizeEstimator.scala:285)\n\tat org.apache.spark.util.SizeEstimator$$$Lambda$2199/1314312644.apply$mcVI$sp(Unknown Source)\n\tat scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:158)\n\tat org.apache.spark.util.SizeEstimator$.sampleArray(SizeEstimator.scala:277)\n\tat org.apache.spark.util.SizeEstimator$.visitArray(SizeEstimator.scala:261)\n\tat org.apache.spark.util.SizeEstimator$.visitSingleObject(SizeEstimator.scala:209)\n\tat org.apache.spark.util.SizeEstimator$.estimate(SizeEstimator.scala:201)\n\tat org.apache.spark.util.SizeEstimator$.estimate(SizeEstimator.scala:68)\n\tat org.apache.spark.util.collection.SizeTracker.takeSample(SizeTracker.scala:78)\n\tat org.apache.spark.util.collection.SizeTracker.afterUpdate(SizeTracker.scala:70)\n\tat org.apache.spark.util.collection.SizeTracker.afterUpdate$(SizeTracker.scala:67)\n\tat org.apache.spark.util.collection.SizeTrackingAppendOnlyMap.changeValue(SizeTrackingAppendOnlyMap.scala:33)\n\tat org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:164)\n\tat org.apache.spark.Aggregator.combineCombinersByKey(Aggregator.scala:50)\n\tat org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:116)\n\tat org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:106)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "----------------------------------------\n",
            "Exception occurred during processing of request from ('127.0.0.1', 45168)\n",
            "ERROR:root:Exception while sending command.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-3.3.2-bin-hadoop3/python/lib/py4j-0.10.9.5-src.zip/py4j/clientserver.py\", line 516, in send_command\n",
            "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
            "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/spark-3.3.2-bin-hadoop3/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py\", line 1038, in send_command\n",
            "    response = connection.send_command(command)\n",
            "  File \"/content/spark-3.3.2-bin-hadoop3/python/lib/py4j-0.10.9.5-src.zip/py4j/clientserver.py\", line 539, in send_command\n",
            "    raise Py4JNetworkError(\n",
            "py4j.protocol.Py4JNetworkError: Error while sending or receiving\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.9/socketserver.py\", line 316, in _handle_request_noblock\n",
            "    self.process_request(request, client_address)\n",
            "  File \"/usr/lib/python3.9/socketserver.py\", line 347, in process_request\n",
            "    self.finish_request(request, client_address)\n",
            "  File \"/usr/lib/python3.9/socketserver.py\", line 360, in finish_request\n",
            "    self.RequestHandlerClass(request, client_address, self)\n",
            "  File \"/usr/lib/python3.9/socketserver.py\", line 747, in __init__\n",
            "    self.handle()\n",
            "  File \"/content/spark-3.3.2-bin-hadoop3/python/pyspark/accumulators.py\", line 281, in handle\n",
            "    poll(accum_updates)\n",
            "  File \"/content/spark-3.3.2-bin-hadoop3/python/pyspark/accumulators.py\", line 253, in poll\n",
            "    if func():\n",
            "  File \"/content/spark-3.3.2-bin-hadoop3/python/pyspark/accumulators.py\", line 257, in accum_updates\n",
            "    num_updates = read_int(self.rfile)\n",
            "  File \"/content/spark-3.3.2-bin-hadoop3/python/pyspark/serializers.py\", line 595, in read_int\n",
            "    raise EOFError\n",
            "EOFError\n",
            "----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Pre-processing - Article "
      ],
      "metadata": {
        "id": "_ub20rYjYc4B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark \\\n",
        "    .read \\\n",
        "    .format(\"csv\") \\\n",
        "    .option(\"header\", True) \\\n",
        "    .load(\"/content/CNN/cnn_dailymail\")\n",
        "\n",
        "df.printSchema()"
      ],
      "metadata": {
        "id": "ZLlzEMKsaCSs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de444fca-1523-49de-c7bc-985b40ed7a43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- id: string (nullable = true)\n",
            " |-- article: string (nullable = true)\n",
            " |-- highlights: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.dropna()"
      ],
      "metadata": {
        "id": "KYByGQiJaZq1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.count()"
      ],
      "metadata": {
        "id": "bBDBS0oAlgnF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eac217b0-7a80-49c2-9093-087fc71d4c4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "382518"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.withColumnRenamed(\"article\", \"text\")"
      ],
      "metadata": {
        "id": "NMHxcoNLaiZw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import Tokenizer,StopWordsRemover, CountVectorizer,IDF,StringIndexer\n",
        "from pyspark.ml.feature import Tokenizer, RegexTokenizer\n",
        "from pyspark.sql.functions import col, udf, concat_ws\n",
        "from pyspark.sql.types import IntegerType\n",
        "\n",
        "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"tokens\")\n",
        "regexTokenizer = RegexTokenizer(inputCol=\"text\", outputCol=\"tokens\", pattern=\"\\\\W\")\n",
        "stopremove = StopWordsRemover(inputCol='tokens',outputCol='cleaned')"
      ],
      "metadata": {
        "id": "rI230WfaU4YR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml import Pipeline\n",
        "data_prep_pipe = Pipeline(stages=[regexTokenizer, stopremove ])\n",
        "cleaner = data_prep_pipe.fit(df)\n",
        "df = cleaner.transform(df)"
      ],
      "metadata": {
        "id": "cFfjIyroU4Qp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.show(5)"
      ],
      "metadata": {
        "id": "2naSUovQbANc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7b001fd-78d7-4fe2-de6b-f41e2db877db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|                  id|                text|          highlights|              tokens|             cleaned|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|0001d1afc246a7964...|By . Associated P...|Bishop John Folda...|[by, associated, ...|[associated, pres...|\n",
            "|0002095e55fcbd3a2...|\"(CNN) -- Ralph M...|\"\" of using his r...|[cnn, ralph, mata...|[cnn, ralph, mata...|\n",
            "|          Ralph Mata| an internal affa...| allegedly helped...|[an, internal, af...|[internal, affair...|\n",
            "|00027e965c8264c35...|A drunk driver wh...|Craig Eccleston-T...|[a, drunk, driver...|[drunk, driver, k...|\n",
            "|0002c17436637c4fe...|(CNN) -- With a b...|Nina dos Santos s...|[cnn, with, a, br...|[cnn, breezy, swe...|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df['text','cleaned']"
      ],
      "metadata": {
        "id": "8odfZ2n6bYw_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUvZZxI8MYYt",
        "outputId": "0bb10b92-45c9-4423-a742-ea417a8de48e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "382518"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import monotonically_increasing_id \n",
        "\n",
        "df = df.select(\"*\").withColumn(\"id\", monotonically_increasing_id())"
      ],
      "metadata": {
        "id": "ESUftiM2bi73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import IntegerType\n",
        "from pyspark.sql.functions import collect_set, array_distinct\n",
        "from pyspark.ml.fpm import FPGrowth\n",
        "import timeit\n",
        "\n"
      ],
      "metadata": {
        "id": "lpXoC763iBEb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Models for 10 articles\n"
      ],
      "metadata": {
        "id": "ZBQvhqcbdkuf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = df.where(df.id < 10)"
      ],
      "metadata": {
        "id": "5i4lYvpkbyCr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.count()"
      ],
      "metadata": {
        "id": "I-YTeDzLcJ5V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd460910-278f-43c1-aa3a-ef7d47d0ed7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1.show()"
      ],
      "metadata": {
        "id": "UGb__IS5dUPp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "973c8fc1-cc33-4952-c587-26ae1a45acea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+---+\n",
            "|                text|             cleaned| id|\n",
            "+--------------------+--------------------+---+\n",
            "|By . Associated P...|[associated, pres...|  0|\n",
            "|\"(CNN) -- Ralph M...|[cnn, ralph, mata...|  1|\n",
            "| an internal affa...|[internal, affair...|  2|\n",
            "|A drunk driver wh...|[drunk, driver, k...|  3|\n",
            "|(CNN) -- With a b...|[cnn, breezy, swe...|  4|\n",
            "|Fleetwood are the...|[fleetwood, team,...|  5|\n",
            "|        Bristol City|     [bristol, city]|  6|\n",
            "|He's been accused...|[accused, making,...|  7|\n",
            "|By . Daily Mail R...|[daily, mail, rep...|  8|\n",
            "|\"By . Daily Mail ...|[daily, mail, rep...|  9|\n",
            "+--------------------+--------------------+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "baskets = df1.select(array_distinct(df1.cleaned)).collect()\n",
        "baskets = spark.createDataFrame(baskets)\n",
        "start = timeit.default_timer()\n",
        "fpGrowth = FPGrowth(minSupport=0.05, minConfidence=1, itemsCol=\"array_distinct(cleaned)\")\n",
        "model = fpGrowth.fit(baskets)\n",
        "model.freqItemsets.show(10)\n",
        "article_10 = timeit.default_timer() - start"
      ],
      "metadata": {
        "id": "TEnYsixVarEQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78efa215-498f-48d4-eda6-bc29443aabcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+----+\n",
            "|               items|freq|\n",
            "+--------------------+----+\n",
            "|        [atmosphere]|   1|\n",
            "|[atmosphere, gips...|   1|\n",
            "|[atmosphere, gips...|   1|\n",
            "|[atmosphere, gips...|   1|\n",
            "|[atmosphere, gips...|   1|\n",
            "|[atmosphere, gips...|   1|\n",
            "|[atmosphere, gips...|   1|\n",
            "|[atmosphere, gips...|   1|\n",
            "|[atmosphere, gips...|   1|\n",
            "|[atmosphere, gips...|   1|\n",
            "+--------------------+----+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "article_10"
      ],
      "metadata": {
        "id": "mWZ4yM1sdR4_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57951183-ef11-4caf-a289-29cdd7b6b71d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.6151313370000935"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Model with 100 articles\n",
        "\n"
      ],
      "metadata": {
        "id": "ToxWdxhfes-N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = df.where(df.id < 100)"
      ],
      "metadata": {
        "id": "KHoj4WiyJG_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WzYe8ofIJOcG",
        "outputId": "3303710b-a8a5-4aca-e8f6-4cc426c5b378"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "baskets = df2.select(array_distinct(df2.cleaned)).collect()\n",
        "baskets = spark.createDataFrame(baskets)\n",
        "start = timeit.default_timer()\n",
        "fpGrowth = FPGrowth(minSupport=0.05, minConfidence=1, itemsCol=\"array_distinct(cleaned)\")\n",
        "model = fpGrowth.fit(baskets)\n",
        "model.freqItemsets.show(10)\n",
        "article_100 = timeit.default_timer() - start\n",
        "\n"
      ],
      "metadata": {
        "id": "a2YOVNJWd0n_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f09a9fd4-5c77-4da7-fb05-6f799a91ac4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+----+\n",
            "|               items|freq|\n",
            "+--------------------+----+\n",
            "|              [need]|   5|\n",
            "|        [need, like]|   5|\n",
            "|              [good]|  12|\n",
            "|        [good, next]|   7|\n",
            "| [good, next, first]|   5|\n",
            "|[good, next, firs...|   5|\n",
            "|  [good, next, year]|   6|\n",
            "|[good, next, year...|   6|\n",
            "|  [good, next, made]|   5|\n",
            "|[good, next, made...|   5|\n",
            "+--------------------+----+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "article_100"
      ],
      "metadata": {
        "id": "uftfQ1VufM8M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60971e29-9c06-4438-ea6d-ff978f78a2c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.764393119000033"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.associationRules.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ydvNLKQJeaJ",
        "outputId": "4dd6bbf2-ae80-4bdc-c3c6-95fb1cf575d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+----------+----------+------------------+-------+\n",
            "|          antecedent|consequent|confidence|              lift|support|\n",
            "+--------------------+----------+----------+------------------+-------+\n",
            "|[think, people, y...|    [four]|       1.0|  5.88235294117647|   0.05|\n",
            "|[published, home,...|    [said]|       1.0| 1.923076923076923|   0.05|\n",
            "|[published, home,...|    [time]|       1.0|2.7777777777777777|   0.05|\n",
            "|[day, last, two, ...|   [court]|       1.0| 11.11111111111111|   0.05|\n",
            "|[day, last, two, ...|    [said]|       1.0| 1.923076923076923|   0.05|\n",
            "|[told, years, two...|     [day]|       1.0| 3.846153846153846|   0.05|\n",
            "|[told, years, two...|    [time]|       1.0|2.7777777777777777|   0.05|\n",
            "|[told, years, two...|    [year]|       1.0|               2.5|   0.05|\n",
            "|[told, years, two...|    [said]|       1.0| 1.923076923076923|   0.05|\n",
            "|[published, updat...|     [est]|       1.0| 7.692307692307692|   0.06|\n",
            "|[2013, est, publi...|    [home]|       1.0| 4.166666666666667|   0.05|\n",
            "|[2013, est, publi...|    [year]|       1.0|               2.5|   0.05|\n",
            "|[2013, est, publi...|    [said]|       1.0| 1.923076923076923|   0.05|\n",
            "|[2013, est, publi...|   [years]|       1.0|3.2258064516129035|   0.05|\n",
            "|[want, 000, take,...|   [first]|       1.0|3.4482758620689657|   0.05|\n",
            "|[want, 000, take,...|    [many]|       1.0|              6.25|   0.05|\n",
            "|  [taken, two, also]|    [home]|       1.0| 4.166666666666667|   0.05|\n",
            "|  [taken, two, also]|     [day]|       1.0| 3.846153846153846|   0.05|\n",
            "|  [taken, two, also]|    [year]|       1.0|               2.5|   0.05|\n",
            "|  [taken, two, also]|     [000]|       1.0|              6.25|   0.05|\n",
            "+--------------------+----------+----------+------------------+-------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Model with 1000 articles"
      ],
      "metadata": {
        "id": "esF64TyufWMJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df3 = df.where(df.id < 1000)\n",
        "baskets = df3.select(array_distinct(df3.cleaned)).collect()\n",
        "baskets = spark.createDataFrame(baskets)\n",
        "start = timeit.default_timer()\n",
        "fpGrowth = FPGrowth(minSupport=0.05, minConfidence=1, itemsCol=\"array_distinct(cleaned)\")\n",
        "model = fpGrowth.fit(baskets)\n",
        "model.freqItemsets.show(10)\n",
        "article_1000 = timeit.default_timer() - start\n"
      ],
      "metadata": {
        "id": "jGG8DyHFfVpV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa076ae5-5ccf-4f18-9f42-3c0453683593"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+----+\n",
            "|               items|freq|\n",
            "+--------------------+----+\n",
            "|              [want]| 127|\n",
            "|       [want, right]|  56|\n",
            "| [want, right, said]|  50|\n",
            "|       [want, first]|  56|\n",
            "|        [want, know]|  50|\n",
            "|        [want, told]|  52|\n",
            "|        [want, back]|  53|\n",
            "|        [want, year]|  82|\n",
            "|   [want, year, one]|  67|\n",
            "|[want, year, one,...|  60|\n",
            "+--------------------+----+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df3.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6fqy94hBMfjq",
        "outputId": "5b45008b-1762-41da-c9cd-335ad320c234"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "article_1000"
      ],
      "metadata": {
        "id": "UU9RE_1GfVjB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2668113-e974-4c88-83ed-ec73d39f4b9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.433014306000132"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.associationRules.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LlValeEgJxqc",
        "outputId": "71f203cc-ee66-43ba-fdb2-f05d4d76725a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----------+----------+------------------+-------+\n",
            "|          antecedent| consequent|confidence|              lift|support|\n",
            "+--------------------+-----------+----------+------------------+-------+\n",
            "|[est, published, ...|  [updated]|       1.0| 5.780346820809249|  0.055|\n",
            "|[2013, est, updat...|[published]|       1.0|  5.46448087431694|   0.07|\n",
            "|[home, three, tol...|     [said]|       1.0|1.8083182640144664|   0.05|\n",
            "|[later, told, old...|     [year]|       1.0| 2.347417840375587|  0.053|\n",
            "|[2013, est, publi...|  [updated]|       1.0| 5.780346820809249|  0.054|\n",
            "|[est, published, ...|  [updated]|       1.0| 5.780346820809249|  0.052|\n",
            "|[right, left, tol...|     [said]|       1.0|1.8083182640144664|  0.054|\n",
            "|       [work, added]|     [said]|       1.0|1.8083182640144664|  0.052|\n",
            "|[est, published, ...|  [updated]|       1.0| 5.780346820809249|  0.053|\n",
            "|   [spokesman, year]|     [said]|       1.0|1.8083182640144664|  0.058|\n",
            "|[est, left, year,...|  [updated]|       1.0| 5.780346820809249|  0.063|\n",
            "|[est, published, ...|  [updated]|       1.0| 5.780346820809249|  0.055|\n",
            "|[updated, publish...|      [est]|       1.0| 6.211180124223603|  0.064|\n",
            "|[years, old, two,...|     [year]|       1.0| 2.347417840375587|  0.051|\n",
            "|[est, updated, fo...|[published]|       1.0|  5.46448087431694|   0.05|\n",
            "|   [est, home, year]|  [updated]|       1.0| 5.780346820809249|  0.054|\n",
            "|[updated, publish...|      [est]|       1.0| 6.211180124223603|  0.055|\n",
            "|[three, old, time...|     [year]|       1.0| 2.347417840375587|  0.059|\n",
            "|[three, told, old...|     [year]|       1.0| 2.347417840375587|  0.053|\n",
            "|          [est, new]|  [updated]|       1.0| 5.780346820809249|  0.064|\n",
            "+--------------------+-----------+----------+------------------+-------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calculating the average number of tokens per article"
      ],
      "metadata": {
        "id": "w_hCwDf9bkJb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "count_tokens = udf(lambda words:len(words), IntegerType())\n",
        "baskets = baskets.withColumn('count', count_tokens(col('array_distinct(cleaned)')))\n",
        "baskets.describe().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_4X-POjItQZ",
        "outputId": "4a5fe931-2182-4778-df86-e96af83ba7ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------------+\n",
            "|summary|             count|\n",
            "+-------+------------------+\n",
            "|  count|              1000|\n",
            "|   mean|           149.276|\n",
            "| stddev|128.33184673683647|\n",
            "|    min|                 1|\n",
            "|    max|               614|\n",
            "+-------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Model with 5000 articles"
      ],
      "metadata": {
        "id": "maQ0ZA1ghxCz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df5 = df.where(df.id < 5000)\n",
        "\n",
        "baskets = df5.select(array_distinct(df5.cleaned)).collect()\n",
        "baskets = spark.createDataFrame(baskets)\n",
        "start = timeit.default_timer()\n",
        "fpGrowth = FPGrowth(minSupport=0.05, minConfidence=1, itemsCol=\"array_distinct(cleaned)\")\n",
        "model = fpGrowth.fit(baskets)\n",
        "model.freqItemsets.show(10)\n",
        "article_5000 = timeit.default_timer() - start"
      ],
      "metadata": {
        "id": "n4TnjG9th3P0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7aa2e572-60a4-47cb-86cf-dd7a9b6520fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+----+\n",
            "|               items|freq|\n",
            "+--------------------+----+\n",
            "|           [however]| 668|\n",
            "|     [however, like]| 262|\n",
            "|      [however, new]| 323|\n",
            "|[however, new, said]| 279|\n",
            "|     [however, told]| 313|\n",
            "|[however, told, s...| 288|\n",
            "|     [however, year]| 429|\n",
            "|[however, year, one]| 320|\n",
            "|[however, year, o...| 279|\n",
            "|[however, year, s...| 373|\n",
            "+--------------------+----+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df5.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FKqHVZoeMlp2",
        "outputId": "c45bf76c-df07-41df-d448-af0ae5b098fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5000"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "article_5000"
      ],
      "metadata": {
        "id": "RDcv0qbnh3Ng",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fdde3d5-e40a-4acf-c054-c379c67c09b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14.432767931999933"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.associationRules.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qiZxi9g_KIB8",
        "outputId": "b7cab64e-61a3-497f-c855-0a5af195c2b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----------+----------+-----------------+-------+\n",
            "|          antecedent| consequent|confidence|             lift|support|\n",
            "+--------------------+-----------+----------+-----------------+-------+\n",
            "|[est, published, ...|  [updated]|       1.0|5.359056806002144|  0.062|\n",
            "|[2013, est, updat...|[published]|       1.0| 5.09683995922528| 0.0632|\n",
            "|[est, published, ...|  [updated]|       1.0|5.359056806002144| 0.0564|\n",
            "|[est, left, year,...|  [updated]|       1.0|5.359056806002144| 0.0548|\n",
            "|[est, published, ...|  [updated]|       1.0|5.359056806002144| 0.0572|\n",
            "|[updated, publish...|      [est]|       1.0|5.773672055427252| 0.0694|\n",
            "|[10, est, published]|  [updated]|       1.0|5.359056806002144| 0.0568|\n",
            "|[updated, publish...|      [est]|       1.0|5.773672055427252|  0.062|\n",
            "|          [est, new]|  [updated]|       1.0|5.359056806002144| 0.0738|\n",
            "|[est, published, ...|  [updated]|       1.0|5.359056806002144| 0.0608|\n",
            "|         [est, life]|  [updated]|       1.0|5.359056806002144| 0.0548|\n",
            "|   [est, life, said]|  [updated]|       1.0|5.359056806002144| 0.0508|\n",
            "|[2013, est, updat...|[published]|       1.0| 5.09683995922528| 0.0554|\n",
            "|   [2013, est, time]|[published]|       1.0| 5.09683995922528| 0.0556|\n",
            "|[mr, est, publish...|  [updated]|       1.0|5.359056806002144|  0.054|\n",
            "|[est, published, ...|  [updated]|       1.0|5.359056806002144| 0.0504|\n",
            "|[2013, updated, p...|      [est]|       1.0|5.773672055427252| 0.0518|\n",
            "|   [2013, est, last]|  [updated]|       1.0|5.359056806002144| 0.0518|\n",
            "|[2013, updated, p...|      [est]|       1.0|5.773672055427252| 0.0554|\n",
            "|[est, published, ...|  [updated]|       1.0|5.359056806002144| 0.0552|\n",
            "+--------------------+-----------+----------+-----------------+-------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model with 7500 articles"
      ],
      "metadata": {
        "id": "aGoeYN0XkOTE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df6 = df.where(df.id < 7500)\n",
        "\n",
        "baskets = df6.select(array_distinct(df6.cleaned)).collect()\n",
        "baskets = spark.createDataFrame(baskets)\n",
        "\n",
        "start = timeit.default_timer()\n",
        "fpGrowth = FPGrowth(minSupport=0.05, minConfidence=1, itemsCol=\"array_distinct(cleaned)\")\n",
        "model = fpGrowth.fit(baskets)\n",
        "model.freqItemsets.show(10)\n",
        "article_7500 = timeit.default_timer() - start"
      ],
      "metadata": {
        "id": "fpSEQybBh3Ks",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "349cab79-1577-4da0-aea2-06c995057c7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+----+\n",
            "|               items|freq|\n",
            "+--------------------+----+\n",
            "|              [went]| 988|\n",
            "|        [went, made]| 395|\n",
            "|         [went, new]| 412|\n",
            "|      [went, people]| 437|\n",
            "|[went, people, said]| 392|\n",
            "|        [went, year]| 686|\n",
            "|   [went, year, one]| 504|\n",
            "|[went, year, one,...| 451|\n",
            "|  [went, year, said]| 601|\n",
            "|        [went, last]| 573|\n",
            "+--------------------+----+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df6.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Z8ahd1zMquM",
        "outputId": "941d1897-c4b3-4244-9987-d3aa713681ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7500"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "article_7500"
      ],
      "metadata": {
        "id": "vylgUG2kh3IA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbd359f0-5b0a-41ce-c082-70906195eaaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19.868800029999875"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.associationRules.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-jvx-ZFOKRUa",
        "outputId": "1b0bf389-c241-4ba6-ec4f-bbb105c5071f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----------+----------+-----------------+--------------------+\n",
            "|          antecedent| consequent|confidence|             lift|             support|\n",
            "+--------------------+-----------+----------+-----------------+--------------------+\n",
            "|[est, published, ...|  [updated]|       1.0|5.289139633286319|              0.0612|\n",
            "|[2013, est, updat...|[published]|       1.0|5.091649694501019| 0.06506666666666666|\n",
            "|[est, published, ...|  [updated]|       1.0|5.289139633286319|0.054266666666666664|\n",
            "|[est, published, ...|  [updated]|       1.0|5.289139633286319|0.056933333333333336|\n",
            "|[10, est, published]|  [updated]|       1.0|5.289139633286319| 0.05893333333333333|\n",
            "|[est, published, ...|  [updated]|       1.0|5.289139633286319| 0.05973333333333333|\n",
            "|[2013, est, updat...|[published]|       1.0|5.091649694501019| 0.05506666666666667|\n",
            "|   [2013, est, time]|[published]|       1.0|5.091649694501019|              0.0552|\n",
            "|[mr, est, publish...|  [updated]|       1.0|5.289139633286319|0.055466666666666664|\n",
            "|[est, published, ...|  [updated]|       1.0|5.289139633286319|              0.0512|\n",
            "|[2013, updated, p...|      [est]|       1.0|5.673222390317701| 0.05333333333333334|\n",
            "|   [2013, est, last]|  [updated]|       1.0|5.289139633286319| 0.05226666666666667|\n",
            "|[family, est, pub...|  [updated]|       1.0|5.289139633286319| 0.05333333333333334|\n",
            "|[2013, updated, p...|      [est]|       1.0|5.673222390317701| 0.05506666666666667|\n",
            "|[est, published, ...|  [updated]|       1.0|5.289139633286319| 0.05533333333333333|\n",
            "|[est, published, ...|  [updated]|       1.0|5.289139633286319| 0.05173333333333333|\n",
            "|[est, years, year...|  [updated]|       1.0|5.289139633286319|              0.0584|\n",
            "|[est, published, ...|  [updated]|       1.0|5.289139633286319|0.050133333333333335|\n",
            "|[est, published, ...|  [updated]|       1.0|5.289139633286319|                0.05|\n",
            "|[est, published, ...|  [updated]|       1.0|5.289139633286319|              0.0712|\n",
            "+--------------------+-----------+----------+-----------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Model with 10000 articles"
      ],
      "metadata": {
        "id": "RdArPWlaf3iW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df7 = df.where(df.id < 10000)\n",
        "\n",
        "baskets = df7.select(array_distinct(df7.cleaned)).collect()\n",
        "baskets = spark.createDataFrame(baskets)\n",
        "start = timeit.default_timer()\n",
        "fpGrowth = FPGrowth(minSupport=0.05, minConfidence=1, itemsCol=\"array_distinct(cleaned)\")\n",
        "model = fpGrowth.fit(baskets)\n",
        "model.freqItemsets.show(10)\n",
        "article_10000 = timeit.default_timer() - start"
      ],
      "metadata": {
        "id": "SFXWbboPfzPj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62e162fd-c325-4ad0-bb12-36e5c7f57825"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+----+\n",
            "|               items|freq|\n",
            "+--------------------+----+\n",
            "|              [says]|1308|\n",
            "|        [says, made]| 506|\n",
            "|         [says, new]| 644|\n",
            "|   [says, new, said]| 549|\n",
            "|      [says, people]| 647|\n",
            "|[says, people, said]| 553|\n",
            "|        [says, year]| 847|\n",
            "|   [says, year, one]| 626|\n",
            "|[says, year, one,...| 545|\n",
            "|  [says, year, said]| 729|\n",
            "+--------------------+----+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df7.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NwJcCBvPMvjp",
        "outputId": "7d6f0cca-c18d-4bac-80bd-4db92edfde35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "article_10000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7Ilp9yXKriV",
        "outputId": "45f7873c-542d-4b9d-b588-7b2c8eedc10a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28.613862445999985"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.associationRules.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rxvrxSlFKxdP",
        "outputId": "da52ccae-5c74-4abc-f62d-1cfd42929ad2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+----------+----------+----------------+-------+\n",
            "|          antecedent|consequent|confidence|            lift|support|\n",
            "+--------------------+----------+----------+----------------+-------+\n",
            "|[est, published, ...| [updated]|       1.0|5.31632110579479| 0.0599|\n",
            "|[est, published, ...| [updated]|       1.0|5.31632110579479| 0.0526|\n",
            "|[est, published, ...| [updated]|       1.0|5.31632110579479| 0.0546|\n",
            "|[10, est, published]| [updated]|       1.0|5.31632110579479| 0.0582|\n",
            "|[est, published, ...| [updated]|       1.0|5.31632110579479|  0.058|\n",
            "|[mr, est, publish...| [updated]|       1.0|5.31632110579479| 0.0539|\n",
            "|[2013, updated, p...|     [est]|       1.0|5.74712643678161| 0.0544|\n",
            "|   [2013, est, last]| [updated]|       1.0|5.31632110579479| 0.0521|\n",
            "|[family, est, pub...| [updated]|       1.0|5.31632110579479| 0.0509|\n",
            "|[2013, updated, p...|     [est]|       1.0|5.74712643678161| 0.0543|\n",
            "|[est, published, ...| [updated]|       1.0|5.31632110579479| 0.0531|\n",
            "|[est, published, ...| [updated]|       1.0|5.31632110579479|  0.051|\n",
            "|[est, published, ...| [updated]|       1.0|5.31632110579479| 0.0505|\n",
            "|[est, published, ...| [updated]|       1.0|5.31632110579479| 0.0696|\n",
            "|[2013, updated, p...|     [est]|       1.0|5.74712643678161|  0.054|\n",
            "|[est, published, ...| [updated]|       1.0|5.31632110579479| 0.0512|\n",
            "|[2013, updated, p...|     [est]|       1.0|5.74712643678161| 0.0517|\n",
            "|         [life, est]| [updated]|       1.0|5.31632110579479| 0.0526|\n",
            "|[family, est, pub...| [updated]|       1.0|5.31632110579479| 0.0556|\n",
            "|[2013, updated, p...|     [est]|       1.0|5.74712643678161|   0.06|\n",
            "+--------------------+----------+----------+----------------+-------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model with 50000 articles"
      ],
      "metadata": {
        "id": "UWGY0-MfLMww"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df8 = df.where(df.id < 50000)\n",
        "\n",
        "baskets = df8.select(array_distinct(df8.cleaned)).collect()\n",
        "baskets = spark.createDataFrame(baskets)\n",
        "\n",
        "start = timeit.default_timer()\n",
        "fpGrowth = FPGrowth(minSupport=0.05, minConfidence=1, itemsCol=\"array_distinct(cleaned)\")\n",
        "model = fpGrowth.fit(baskets)\n",
        "model.freqItemsets.show(10)\n",
        "article_50000 = timeit.default_timer() - start"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lH7NFeTeLLgD",
        "outputId": "37822c64-4ba0-41de-f93b-9d592a922775"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "Py4JJavaError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-66-079e9f0f3000>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mfpGrowth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFPGrowth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminSupport\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminConfidence\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitemsCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"array_distinct(cleaned)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfpGrowth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbaskets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfreqItemsets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0marticle_50000\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimeit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_timer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.3.2-bin-hadoop3/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtruncate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 606\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    607\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.3.2-bin-hadoop3/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1322\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.3.2-bin-hadoop3/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/spark-3.3.2-bin-hadoop3/python/lib/py4j-0.10.9.5-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOUTPUT_CONVERTER\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway_client\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mREFERENCE_TYPE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m                 raise Py4JJavaError(\n\u001b[0m\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m                     format(target_id, \".\", name), value)\n",
            "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o807.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 2 in stage 134.0 failed 1 times, most recent failure: Lost task 2.0 in stage 134.0 (TID 535) (ee1a793c14a9 executor driver): java.lang.OutOfMemoryError: Java heap space\n\tat java.util.IdentityHashMap.resize(IdentityHashMap.java:474)\n\tat java.util.IdentityHashMap.put(IdentityHashMap.java:443)\n\tat org.apache.spark.util.SizeEstimator$SearchState.enqueue(SizeEstimator.scala:174)\n\tat org.apache.spark.util.SizeEstimator$.$anonfun$visitSingleObject$1(SizeEstimator.scala:225)\n\tat org.apache.spark.util.SizeEstimator$.$anonfun$visitSingleObject$1$adapted(SizeEstimator.scala:224)\n\tat org.apache.spark.util.SizeEstimator$$$Lambda$981/1353861107.apply(Unknown Source)\n\tat scala.collection.immutable.List.foreach(List.scala:431)\n\tat org.apache.spark.util.SizeEstimator$.visitSingleObject(SizeEstimator.scala:224)\n\tat org.apache.spark.util.SizeEstimator$.estimate(SizeEstimator.scala:201)\n\tat org.apache.spark.util.SizeEstimator$.estimate(SizeEstimator.scala:68)\n\tat org.apache.spark.util.collection.SizeTracker.takeSample(SizeTracker.scala:78)\n\tat org.apache.spark.util.collection.SizeTracker.afterUpdate(SizeTracker.scala:70)\n\tat org.apache.spark.util.collection.SizeTracker.afterUpdate$(SizeTracker.scala:67)\n\tat org.apache.spark.util.collection.SizeTrackingAppendOnlyMap.changeValue(SizeTrackingAppendOnlyMap.scala:33)\n\tat org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:200)\n\tat org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:136)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)\n\tat org.apache.spark.executor.Executor$TaskRunner$$Lambda$2528/941265432.apply(Unknown Source)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2672)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2608)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2607)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2607)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1182)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1182)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1182)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2860)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2802)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2791)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:952)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2238)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2259)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2278)\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:506)\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:459)\n\tat org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:48)\n\tat org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:3868)\n\tat org.apache.spark.sql.Dataset.$anonfun$head$1(Dataset.scala:2863)\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$2(Dataset.scala:3858)\n\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:510)\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3856)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:109)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:169)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:95)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:779)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3856)\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:2863)\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:3084)\n\tat org.apache.spark.sql.Dataset.getRows(Dataset.scala:288)\n\tat org.apache.spark.sql.Dataset.showString(Dataset.scala:327)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: java.lang.OutOfMemoryError: Java heap space\n\tat java.util.IdentityHashMap.resize(IdentityHashMap.java:474)\n\tat java.util.IdentityHashMap.put(IdentityHashMap.java:443)\n\tat org.apache.spark.util.SizeEstimator$SearchState.enqueue(SizeEstimator.scala:174)\n\tat org.apache.spark.util.SizeEstimator$.$anonfun$visitSingleObject$1(SizeEstimator.scala:225)\n\tat org.apache.spark.util.SizeEstimator$.$anonfun$visitSingleObject$1$adapted(SizeEstimator.scala:224)\n\tat org.apache.spark.util.SizeEstimator$$$Lambda$981/1353861107.apply(Unknown Source)\n\tat scala.collection.immutable.List.foreach(List.scala:431)\n\tat org.apache.spark.util.SizeEstimator$.visitSingleObject(SizeEstimator.scala:224)\n\tat org.apache.spark.util.SizeEstimator$.estimate(SizeEstimator.scala:201)\n\tat org.apache.spark.util.SizeEstimator$.estimate(SizeEstimator.scala:68)\n\tat org.apache.spark.util.collection.SizeTracker.takeSample(SizeTracker.scala:78)\n\tat org.apache.spark.util.collection.SizeTracker.afterUpdate(SizeTracker.scala:70)\n\tat org.apache.spark.util.collection.SizeTracker.afterUpdate$(SizeTracker.scala:67)\n\tat org.apache.spark.util.collection.SizeTrackingAppendOnlyMap.changeValue(SizeTrackingAppendOnlyMap.scala:33)\n\tat org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:200)\n\tat org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:136)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)\n\tat org.apache.spark.executor.Executor$TaskRunner$$Lambda$2528/941265432.apply(Unknown Source)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNN Article Highlights Market Basket Analysis in Pandas"
      ],
      "metadata": {
        "id": "0RE6av9WYO0N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing"
      ],
      "metadata": {
        "id": "7sAvms0hg_Si"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/CNN/cnn_dailymail/test.csv')"
      ],
      "metadata": {
        "id": "SLCI_G_td5iK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = pd.read_csv('/content/CNN/cnn_dailymail/train.csv')\n",
        "df2 = pd.read_csv('/content/CNN/cnn_dailymail/validation.csv')"
      ],
      "metadata": {
        "id": "1zqc55nIigda"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(df2)+len(df)+len(df1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2UvxIQsj5SH",
        "outputId": "4b618d91-a9ee-476a-fe3b-0864a2625297"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "311971"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe = pd.concat([df,df1,df2])"
      ],
      "metadata": {
        "id": "5poWKcQXf4Kt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe = dataframe.dropna(axis=0, how=\"any\")"
      ],
      "metadata": {
        "id": "Ufr7ZJSigQWU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rbrKB8GPjWrw",
        "outputId": "e9923f81-698c-4471-fe7e-64ce52d743b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 311971 entries, 0 to 13367\n",
            "Data columns (total 3 columns):\n",
            " #   Column      Non-Null Count   Dtype \n",
            "---  ------      --------------   ----- \n",
            " 0   id          311971 non-null  object\n",
            " 1   article     311971 non-null  object\n",
            " 2   highlights  311971 non-null  object\n",
            "dtypes: object(3)\n",
            "memory usage: 9.5+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "\n",
        "processed=[]\n",
        "\n",
        "\n",
        "for article in dataframe['highlights']: \n",
        "    article = re.sub('http://\\S+|https://\\S+', \"\", article)\n",
        "    article = re.sub(\"@[A-Za-z0-9]+\",\"\",article) \n",
        "    article = re.sub(r\"www.\\S+\", \"\", article)\n",
        "    \n",
        "    article = re.sub('[^a-zA-Z]', ' ', article) #replacing any punctuation or anything that is not ^ a-z and A-Zletter with the space\n",
        "  \n",
        "    article = article.lower() #lowercase all the words\n",
        "    article = article.split()# splitting the tweet into words\n",
        "\n",
        "      # Stemming the words to keep only the roots using Porter Stemmer \n",
        "    ps = PorterStemmer()\n",
        "    all_stopwords = stopwords.words('english')\n",
        "    all_stopwords.remove('not')\n",
        "    article = [ps.stem(word) for word in article if not word in set(all_stopwords)]\n",
        "    article = ' '.join(article)\n",
        "    processed.append(article)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4AzS-ggYVSR",
        "outputId": "77855911-0942-43ee-dc43-949c406fc6f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['processed'] = processed"
      ],
      "metadata": {
        "id": "6WYUBw9xYVP2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 528
        },
        "id": "sqXRnyidYVKg",
        "outputId": "e7b1e45a-cdd2-4537-8205-61041cde70ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                         id  \\\n",
              "0  92c514c913c0bdfe25341af9fd72b29db544099b   \n",
              "1  2003841c7dc0e7c5b1a248f9cd536d727f27a45a   \n",
              "2  91b7d2311527f5c2b63a65ca98d21d9c92485149   \n",
              "3  caabf9cbdf96eb1410295a673e953d304391bfbb   \n",
              "4  3da746a7d9afcaa659088c8366ef6347fe6b53ea   \n",
              "\n",
              "                                             article  \\\n",
              "0  Ever noticed how plane seats appear to be gett...   \n",
              "1  A drunk teenage boy had to be rescued by secur...   \n",
              "2  Dougie Freedman is on the verge of agreeing a ...   \n",
              "3  Liverpool target Neto is also wanted by PSG an...   \n",
              "4  Bruce Jenner will break his silence in a two-h...   \n",
              "\n",
              "                                          highlights  \\\n",
              "0  Experts question if  packed out planes are put...   \n",
              "1  Drunk teenage boy climbed into lion enclosure ...   \n",
              "2  Nottingham Forest are close to extending Dougi...   \n",
              "3  Fiorentina goalkeeper Neto has been linked wit...   \n",
              "4  Tell-all interview with the reality TV star, 6...   \n",
              "\n",
              "                                           processed  \n",
              "0  expert question pack plane put passeng risk u ...  \n",
              "1  drunk teenag boy climb lion enclosur zoo west ...  \n",
              "2  nottingham forest close extend dougi freedman ...  \n",
              "3  fiorentina goalkeep neto link liverpool arsen ...  \n",
              "4  tell interview realiti tv star air friday apri...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b146921b-6e74-4c35-92e0-9df9787d98d7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>article</th>\n",
              "      <th>highlights</th>\n",
              "      <th>processed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>92c514c913c0bdfe25341af9fd72b29db544099b</td>\n",
              "      <td>Ever noticed how plane seats appear to be gett...</td>\n",
              "      <td>Experts question if  packed out planes are put...</td>\n",
              "      <td>expert question pack plane put passeng risk u ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2003841c7dc0e7c5b1a248f9cd536d727f27a45a</td>\n",
              "      <td>A drunk teenage boy had to be rescued by secur...</td>\n",
              "      <td>Drunk teenage boy climbed into lion enclosure ...</td>\n",
              "      <td>drunk teenag boy climb lion enclosur zoo west ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>91b7d2311527f5c2b63a65ca98d21d9c92485149</td>\n",
              "      <td>Dougie Freedman is on the verge of agreeing a ...</td>\n",
              "      <td>Nottingham Forest are close to extending Dougi...</td>\n",
              "      <td>nottingham forest close extend dougi freedman ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>caabf9cbdf96eb1410295a673e953d304391bfbb</td>\n",
              "      <td>Liverpool target Neto is also wanted by PSG an...</td>\n",
              "      <td>Fiorentina goalkeeper Neto has been linked wit...</td>\n",
              "      <td>fiorentina goalkeep neto link liverpool arsen ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3da746a7d9afcaa659088c8366ef6347fe6b53ea</td>\n",
              "      <td>Bruce Jenner will break his silence in a two-h...</td>\n",
              "      <td>Tell-all interview with the reality TV star, 6...</td>\n",
              "      <td>tell interview realiti tv star air friday apri...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b146921b-6e74-4c35-92e0-9df9787d98d7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b146921b-6e74-4c35-92e0-9df9787d98d7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b146921b-6e74-4c35-92e0-9df9787d98d7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating tokens that can be consumed by apriori alghoritm"
      ],
      "metadata": {
        "id": "uiZLzEERg2RQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = df['processed']"
      ],
      "metadata": {
        "id": "q3UwacrtYVH7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transactions = tokens.str.split()"
      ],
      "metadata": {
        "id": "e84xSbgHYVCU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transactions = [tuple(row) for row in transactions.values.tolist()]"
      ],
      "metadata": {
        "id": "3OuKQbBygukV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating Apriori Models"
      ],
      "metadata": {
        "id": "I6izYI2UhDWm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install efficient_apriori "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NWJZV7ougxbg",
        "outputId": "5101538f-3b22-46a6-dd70-a9c060c6743e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting efficient_apriori\n",
            "  Downloading efficient_apriori-2.0.3-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: efficient_apriori\n",
            "Successfully installed efficient_apriori-2.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from efficient_apriori import apriori"
      ],
      "metadata": {
        "id": "x4rdvohagxYt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start = timeit.default_timer()\n",
        "itemsets, rules = apriori(transactions, min_support=0.05, min_confidence=1)\n",
        "print(rules)\n",
        "highlights_pandas_05 = timeit.default_timer() - start"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fWQO0SxPgxWK",
        "outputId": "37a42fdb-f40b-4d50-ef22-95dccd6ecd16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "highlights_pandas_05 "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQbMNxXlktCA",
        "outputId": "d0045bb3-e978-4450-9040-9c365c3b2060"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.29052923600011127"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start = timeit.default_timer()\n",
        "itemsets, rules = apriori(transactions, min_support=0.005, min_confidence=1)\n",
        "print(rules)\n",
        "highlights_pandas_005 = timeit.default_timer() - start"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xt5b-oHigxN4",
        "outputId": "f2bc48fa-46a7-42d9-b67d-213609b24ec5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{wenger} -> {arsen}, {gaal} -> {van}, {trafford} -> {old}, {raheem} -> {sterl}, {arsen, premier} -> {leagu}, {barcelona, madrid} -> {real}, {chelsea, premier} -> {leagu}, {citi, premier} -> {leagu}, {latest, news} -> {click}, {fa, semi} -> {cup}, {fight, floyd} -> {mayweath}, {floyd, manni} -> {mayweath}, {floyd, pacquiao} -> {mayweath}, {loui, manchest} -> {gaal}, {loui, unit} -> {gaal}, {loui, van} -> {gaal}, {gaal, loui} -> {van}, {gaal, manchest} -> {unit}, {gaal, manchest} -> {van}, {gaal, unit} -> {van}, {game, premier} -> {leagu}, {player, premier} -> {leagu}, {point, premier} -> {leagu}, {premier, saturday} -> {leagu}, {premier, side} -> {leagu}, {premier, top} -> {leagu}, {premier, unit} -> {leagu}, {premier, win} -> {leagu}, {liverpool, raheem} -> {sterl}, {loui, manchest} -> {unit}, {loui, manchest} -> {van}, {loui, unit} -> {van}, {trafford, unit} -> {old}, {citi, manchest, premier} -> {leagu}, {latest, leagu, news} -> {click}, {click, latest, leagu} -> {news}, {fa, final, semi} -> {cup}, {fight, floyd, manni} -> {mayweath}, {fight, floyd, pacquiao} -> {mayweath}, {floyd, manni, pacquiao} -> {mayweath}, {loui, manchest, unit} -> {gaal}, {gaal, loui, manchest} -> {unit}, {loui, manchest} -> {gaal, unit}, {loui, manchest, van} -> {gaal}, {gaal, loui, manchest} -> {van}, {loui, manchest} -> {gaal, van}, {loui, unit, van} -> {gaal}, {gaal, loui, unit} -> {van}, {loui, unit} -> {gaal, van}, {gaal, manchest, van} -> {unit}, {gaal, manchest, unit} -> {van}, {gaal, manchest} -> {unit, van}, {manchest, premier, unit} -> {leagu}, {loui, manchest, van} -> {unit}, {loui, manchest, unit} -> {van}, {loui, manchest} -> {unit, van}, {fight, floyd, manni, pacquiao} -> {mayweath}, {loui, manchest, unit, van} -> {gaal}, {gaal, loui, manchest, van} -> {unit}, {gaal, loui, manchest, unit} -> {van}, {loui, manchest, van} -> {gaal, unit}, {loui, manchest, unit} -> {gaal, van}, {gaal, loui, manchest} -> {unit, van}, {loui, manchest} -> {gaal, unit, van}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "highlights_pandas_005"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_vbrOdtiI8z",
        "outputId": "966aa9b7-04d3-4125-fe5c-5dd7fd694597"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "119.01999203700007"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start = timeit.default_timer()\n",
        "itemsets, rules = apriori(transactions, min_support=0.0005, min_confidence=1)\n",
        "print(rules)\n",
        "highlights_pandas_005 = timeit.default_timer() - start"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZTi_ulDhkw1",
        "outputId": "3f1abe3c-9711-420f-97be-5ae8850a474f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": [
        "bFB_GgxkJTgK",
        "tx9IcYV6E1AX",
        "qNAdu63YDDQR",
        "3coHEwc8TDbK",
        "V711NigqUPci",
        "F9GRkTbHUwIQ",
        "ZBQvhqcbdkuf",
        "ToxWdxhfes-N",
        "esF64TyufWMJ",
        "maQ0ZA1ghxCz",
        "aGoeYN0XkOTE",
        "RdArPWlaf3iW",
        "UWGY0-MfLMww",
        "7sAvms0hg_Si",
        "I6izYI2UhDWm"
      ],
      "authorship_tag": "ABX9TyOVXyXYfUe9BlJsk0apJmsz",
      "include_colab_link": true
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}